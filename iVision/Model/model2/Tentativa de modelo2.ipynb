{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importações\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense, InputLayer, Dropout\n",
    "from skimage.transform import resize\n",
    "from keras.applications.vgg16 import preprocess_input, VGG16\n",
    "from keras.preprocessing import image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from matplotlib import pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Carregar variáveis de ambiente\n",
    "load_dotenv('amb_var.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separação de frames do vídeo de treinamento\n",
    "count = 0\n",
    "videoFile = r\"C:\\Users\\pytho\\Documents\\GitHub\\Icity\\iVision\\Model\\Acidentes-ICity Train - Made with Clipchamp.mp4\"\n",
    "cap = cv2.VideoCapture(videoFile)\n",
    "frameRate = cap.get(5)  # frame rate\n",
    "while(cap.isOpened()):\n",
    "    frameId = cap.get(1)  # current frame number\n",
    "    ret, frame = cap.read()\n",
    "    if (ret != True):\n",
    "        break\n",
    "    if (frameId % math.floor(frameRate) == 0):\n",
    "        filename = \"%d.jpg\" % count\n",
    "        count += 1\n",
    "        cv2.imwrite(filename, frame)\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Leitura do CSV de classificação\u001b[39;00m\n\u001b[0;32m      2\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mmapping_final.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m X \u001b[39m=\u001b[39m [plt\u001b[39m.\u001b[39mimread(\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m img_name) \u001b[39mfor\u001b[39;00m img_name \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39mImage_ID]\n\u001b[0;32m      4\u001b[0m X \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(X)\n\u001b[0;32m      6\u001b[0m y \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mClass\n",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Leitura do CSV de classificação\u001b[39;00m\n\u001b[0;32m      2\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mmapping_final.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m X \u001b[39m=\u001b[39m [plt\u001b[39m.\u001b[39;49mimread(\u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39m+\u001b[39;49m img_name) \u001b[39mfor\u001b[39;00m img_name \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39mImage_ID]\n\u001b[0;32m      4\u001b[0m X \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(X)\n\u001b[0;32m      6\u001b[0m y \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mClass\n",
      "File \u001b[1;32mc:\\Users\\pytho\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\pyplot.py:2195\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(fname, format)\u001b[0m\n\u001b[0;32m   2193\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(matplotlib\u001b[39m.\u001b[39mimage\u001b[39m.\u001b[39mimread)\n\u001b[0;32m   2194\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mimread\u001b[39m(fname, \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m-> 2195\u001b[0m     \u001b[39mreturn\u001b[39;00m matplotlib\u001b[39m.\u001b[39;49mimage\u001b[39m.\u001b[39;49mimread(fname, \u001b[39mformat\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\pytho\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\image.py:1566\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(fname, format)\u001b[0m\n\u001b[0;32m   1558\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1559\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease open the URL for reading and pass the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1560\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mresult to Pillow, e.g. with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1561\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m``np.array(PIL.Image.open(urllib.request.urlopen(url)))``.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1562\u001b[0m         )\n\u001b[0;32m   1563\u001b[0m \u001b[39mwith\u001b[39;00m img_open(fname) \u001b[39mas\u001b[39;00m image:\n\u001b[0;32m   1564\u001b[0m     \u001b[39mreturn\u001b[39;00m (_pil_png_to_float_array(image)\n\u001b[0;32m   1565\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(image, PIL\u001b[39m.\u001b[39mPngImagePlugin\u001b[39m.\u001b[39mPngImageFile) \u001b[39melse\u001b[39;00m\n\u001b[1;32m-> 1566\u001b[0m             pil_to_array(image))\n",
      "File \u001b[1;32mc:\\Users\\pytho\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\image.py:1710\u001b[0m, in \u001b[0;36mpil_to_array\u001b[1;34m(pilImage)\u001b[0m\n\u001b[0;32m   1693\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1694\u001b[0m \u001b[39mLoad a `PIL image`_ and return it as a numpy int array.\u001b[39;00m\n\u001b[0;32m   1695\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1706\u001b[0m \u001b[39m    - (M, N, 4) for RGBA images.\u001b[39;00m\n\u001b[0;32m   1707\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1708\u001b[0m \u001b[39mif\u001b[39;00m pilImage\u001b[39m.\u001b[39mmode \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mRGBA\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mRGBX\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mRGB\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mL\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m   1709\u001b[0m     \u001b[39m# return MxNx4 RGBA, MxNx3 RBA, or MxN luminance array\u001b[39;00m\n\u001b[1;32m-> 1710\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49masarray(pilImage)\n\u001b[0;32m   1711\u001b[0m \u001b[39melif\u001b[39;00m pilImage\u001b[39m.\u001b[39mmode\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39mI;16\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m   1712\u001b[0m     \u001b[39m# return MxN luminance array of uint16\u001b[39;00m\n\u001b[0;32m   1713\u001b[0m     raw \u001b[39m=\u001b[39m pilImage\u001b[39m.\u001b[39mtobytes(\u001b[39m'\u001b[39m\u001b[39mraw\u001b[39m\u001b[39m'\u001b[39m, pilImage\u001b[39m.\u001b[39mmode)\n",
      "File \u001b[1;32mc:\\Users\\pytho\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\PIL\\Image.py:696\u001b[0m, in \u001b[0;36mImage.__array_interface__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    694\u001b[0m         new[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtobytes(\u001b[39m\"\u001b[39m\u001b[39mraw\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mL\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    695\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 696\u001b[0m         new[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtobytes()\n\u001b[0;32m    697\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    698\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(e, (\u001b[39mMemoryError\u001b[39;00m, \u001b[39mRecursionError\u001b[39;00m)):\n",
      "File \u001b[1;32mc:\\Users\\pytho\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\PIL\\Image.py:775\u001b[0m, in \u001b[0;36mImage.tobytes\u001b[1;34m(self, encoder_name, *args)\u001b[0m\n\u001b[0;32m    772\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mencoder error \u001b[39m\u001b[39m{\u001b[39;00merrcode\u001b[39m}\u001b[39;00m\u001b[39m in tobytes\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    773\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg)\n\u001b[1;32m--> 775\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mb\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(output)\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Leitura do CSV de classificação\n",
    "data = pd.read_csv('mapping_final.csv')\n",
    "X = [plt.imread('' + img_name) for img_name in data.Image_ID]\n",
    "X = np.array(X)\n",
    "\n",
    "y = data.Class\n",
    "dummy_y = np_utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessamento das imagens\n",
    "X = [resize(img, preserve_range=True, output_shape=(224, 224)).astype(int) for img in X]\n",
    "X = np.array(X)\n",
    "X = preprocess_input(X, data_format=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão em treino e teste\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, dummy_y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Data Augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "X_train = base_model.predict(X_train)\n",
    "X_valid = base_model.predict(X_valid)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 7 * 7 * 512)\n",
    "X_valid = X_valid.reshape(X_valid.shape[0], 7 * 7 * 512)\n",
    "train = X_train / X_train.max()\n",
    "X_valid = X_valid / X_train.max()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(InputLayer((7 * 7 * 512,)))\n",
    "model.add(Dense(units=1024, activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit_generator(datagen.flow(train, y_train, batch_size=32),\n",
    "                    steps_per_epoch=len(X_train) / 32, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid), callbacks=[early_stop])\n",
    "\n",
    "model.save('Model2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste\n",
    "count = 0\n",
    "videoFile = \"Accident-1.mp4\"\n",
    "cap = cv2.VideoCapture(videoFile)\n",
    "frameRate = cap.get(5)  # frame rate\n",
    "while(cap.isOpened()):\n",
    "    frameId = cap.get(1)  # current frame number\n",
    "    ret, frame = cap.read()\n",
    "    if (ret != True):\n",
    "        break\n",
    "    if (frameId % math.floor(frameRate) == 0):\n",
    "        filename = \"test%d.jpg\" % count\n",
    "        count += 1\n",
    "        cv2.imwrite(filename, frame)\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura de CSV de teste e preprocessamento\n",
    "test = pd.read_csv('test.csv')\n",
    "test_image = [plt.imread('' + img_name) for img_name in test.Image_ID]\n",
    "test_img = np.array(test_image)\n",
    "test_image = [resize(img, preserve_range=True, output_shape=(224, 224)).astype(int) for img in test_img]\n",
    "test_image = preprocess_input(np.array(test_image), data_format=None)\n",
    "test_image = base_model.predict(test_image)\n",
    "test_image = test_image.reshape(test_image.shape[0], 7 * 7 * 512)\n",
    "test_image = test_image / test_image.max()\n",
    "\n",
    "predictions = model.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste em tempo real\n",
    "cap = cv2.VideoCapture('Untitled video - Made with Clipchamp.mp4')\n",
    "i = 0\n",
    "flag = 0\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        if i % 5 == 0:  # Predição a cada 5 frames\n",
    "            if predictions[int(i / 15) % 9][0] < predictions[int(i / 15) % 9][1]:\n",
    "                predict = \"Sem Acidente\"\n",
    "            else:\n",
    "                predict = \"Acidente\"\n",
    "                flag = 1\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            cv2.putText(frame, predict, (50, 50), font, 1, (0, 255, 255), 3, cv2.LINE_4)\n",
    "        cv2.imshow('Frame', frame)\n",
    "        i += 1\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "if flag == 1:\n",
    "    print('Acidente')\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpeza de Imagens\n",
    "def apagar_imagens():\n",
    "    for i in range(5051):\n",
    "        nome_arquivo = f\"{i}.jpg\"\n",
    "        if os.path.exists(nome_arquivo):\n",
    "            os.remove(nome_arquivo)\n",
    "    for i in range(9):\n",
    "        nome_arquivo\n",
    "\n",
    "apagar_imagens()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
